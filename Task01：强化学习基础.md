
# 强化学习基础

### 一、RL相关要素：
#### 1. 两个关键要素：智能体（机器）、环境。
#### 2. 三个附加要素：环境属性：状态、奖赏；机器动作。

### 二、RL决策过程：
#### 是一个有五要素（智能体（机器）、环境、动作、状态、奖励）参与其中的循环往复的序列决策过程。

#### 具体过程如下：
![image|690x317, 50%](upload://2jbBvsJBBuriFen1NZN0MMQzD3B.png) 
图片来自 [蘑菇书EasyRL](https://datawhalechina.github.io/easy-rl/)

#### 既然是“序列决策”过程，也就决定强化学习本身是有序的，前后决策之间具有相关性。

### 三、RL模型及模型要素：
#### 1. 完全可观测环境：马尔可夫决策过程 （Markov decision process，MDP）；
#### 2. 部分可观测环境：部分可观测马尔可夫决策过程（partially observable Markov decision process, POMDP）；

#### 3. 模型要素：
####  （1）策略。
&emsp;<font>根据输出不同，分为：确定性策略（确定值）；随机性策略（概率值）；</font>
#### （2）价值函数。
&emsp;<font>根据已知条件不同，分为：V函数（已知状态）；Q函数（已知状态和动作）；</font>
#### （3）智能体。
&emsp; **根据智能体学习对象不同**，分为： 基于价值的智能体（value-based agent）； 基于策略的智能体（policy-based agent）；

&emsp; **根据环境是否已知**，分为： **有模型（model-based）** 强化学习； **免模型（model-free）** 强化学习；

### 四、其他相关概念：
**1. 学习（learning）和规划（planning）：**
(1) 环境未知是学习过程；环境已知是规划过程。
**(2) “学习与规划”，描述的是模型的构建过程。**

**2. 探索和利用**
**探索和利用，描述的是模型的应用过程。**
